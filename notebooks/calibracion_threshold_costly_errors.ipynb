{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibración de Probabilidades y Selección de Threshold\n",
    "\n",
    "Este notebook forma parte del portafolio y ejemplifica la importancia de calibrar las probabilidades y ajustar el threshold en problemas de clasificación, especialmente cuando equivocarse es muy costoso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\n",
    "Contexto, objetivos y métricas de interés (precisión, recall, AUC, Brier score, costo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problema con alto costo por equivocación\n",
    "Ejemplo: fraude, diagnóstico médico o rechazo de cliente valioso. Definir costos asimétricos para FN y FP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calibración de probabilidades\n",
    "- Platt scaling (sigmoide)\n",
    "- Isotonic regression\n",
    "- Métricas de calibración (Brier score, reliability curve) y validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup inicial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, confusion_matrix, brier_score_loss,\n",
    "                            precision_recall_fscore_support)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "# Datos sintéticos\n",
    "X, y = make_classification(n_samples=4000, n_features=20, n_informative=8, n_redundant=4,\n",
    "                           weights=[0.9, 0.1], class_sep=1.0, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Modelo base\n",
    "base = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "base.fit(X_train, y_train)\n",
    "p_base = base.predict_proba(X_test)[:,1]\n",
    "auc_base = roc_auc_score(y_test, p_base)\n",
    "brier_base = brier_score_loss(y_test, p_base)\n",
    "print(f'AUC base: {auc_base:.3f} | Brier base: {brier_base:.3f}')\n",
    "\n",
    "# Calibración: Platt (sigmoide) e Isotónica\n",
    "platt = CalibratedClassifierCV(base_estimator=LogisticRegression(max_iter=200), method='sigmoid', cv=5)\n",
    "platt.fit(X_train, y_train)\n",
    "p_platt = platt.predict_proba(X_test)[:,1]\n",
    "auc_platt = roc_auc_score(y_test, p_platt); brier_platt = brier_score_loss(y_test, p_platt)\n",
    "\n",
    "iso = CalibratedClassifierCV(base_estimator=LogisticRegression(max_iter=200), method='isotonic', cv=5)\n",
    "iso.fit(X_train, y_train)\n",
    "p_iso = iso.predict_proba(X_test)[:,1]\n",
    "auc_iso = roc_auc_score(y_test, p_iso); brier_iso = brier_score_loss(y_test, p_iso)\n",
    "\n",
    "print(f'AUC platt: {auc_platt:.3f} | Brier platt: {brier_platt:.3f}')\n",
    "print(f'AUC iso:   {auc_iso:.3f} | Brier iso:   {brier_iso:.3f}')\n",
    "\n",
    "# Curvas de calibración\n",
    "def plot_reliability(y_true, p_list, labels):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    for p, lab in zip(p_list, labels):\n",
    "        frac_pos, mean_pred = calibration_curve(y_true, p, n_bins=10)\n",
    "        plt.plot(mean_pred, frac_pos, marker='o', label=lab)\n",
    "    plt.plot([0,1],[0,1],'k--', alpha=0.6)\n",
    "    plt.xlabel('Probabilidad predicha promedio')\n",
    "    plt.ylabel('Fracción positiva')\n",
    "    plt.title('Curva de confiabilidad (calibración)')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_reliability(y_test, [p_base, p_platt, p_iso], ['Base','Platt','Isotónica'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experimentación con thresholds y costo\n",
    "Definir una función de costo asimétrica y evaluar cómo cambia el costo total al variar el threshold. Mostrar matriz de confusión, ROC y curva de costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_metrics(y_true, p, thr, c_fp=1.0, c_fn=10.0):\n",
    "    y_hat = (p >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_hat).ravel()\n",
    "    total_cost = c_fp*fp + c_fn*fn\n",
    "    return {'thr':thr, 'fp':int(fp), 'fn':int(fn), 'tp':int(tp), 'tn':int(tn), 'cost': total_cost}\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.99, 50)\n",
    "rows = []\n",
    "for t in thresholds:\n",
    "    rows.append(cost_metrics(y_test, p_iso, t, c_fp=1.0, c_fn=10.0))\n",
    "df_cost = pd.DataFrame(rows)\n",
    "display(df_cost.head())\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(df_cost['thr'], df_cost['cost'], label='Costo total (Isotónica)')\n",
    "plt.xlabel('Threshold'); plt.ylabel('Costo total'); plt.title('Curva de costo vs threshold')\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# Seleccionar threshold que minimiza costo\n",
    "t_opt = df_cost.loc[df_cost['cost'].idxmin(), 'thr']\n",
    "print(f'Threshold óptimo (mín costo): {t_opt:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusión\n",
    "Resumen de hallazgos: la calibración mejora la confiabilidad de las probabilidades y permite una elección de threshold informada por el costo de error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
